{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018dd09f-4be7-404f-9431-063bbaf1e834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e971ea-1122-4fdb-aac4-15fb317531d4",
   "metadata": {},
   "source": [
    "https://lernapparat.de/jit-optimization-intro/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "7f1f9224-fd90-44c9-906d-4122a607842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 3),\n",
    "            torch.nn.Softplus(),\n",
    "            torch.nn.Linear(3,10),\n",
    "            torch.nn.Softplus(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class mlp_jac(torch.nn.Module):\n",
    "    def __init__(self, mlp):\n",
    "        super().__init__()        \n",
    "        self.mlp = mlp.net\n",
    "\n",
    "        self.linear1 = self.mlp[0]\n",
    "        self.linear2 = self.mlp[2]\n",
    "        \n",
    "        self.linear1_weight = self.linear1.weight\n",
    "        self.linear1_bias   = self.linear1.bias\n",
    "        \n",
    "        self.linear2_weight = self.linear2.weight\n",
    "        self.linear2_bias   = self.linear2.bias\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        jac1, out1 = self.jacobian_onelayer(self.linear1_weight, self.linear1_bias, x)\n",
    "        jac2, out2 = self.jacobian_onelayer(self.linear2_weight, self.linear2_bias, out1)\n",
    "        \n",
    "        jacs = torch.bmm(jac2.permute(2,0,1),jac1.permute(2,0,1))\n",
    "        return jacs\n",
    "#         jacs = torch.einsum(\"xyb, yzb-> xzb\", output_jac2, output_jac1)\n",
    "        \n",
    "        return jac1, jac2\n",
    "    \n",
    "    def jacobian_onelayer(self, W, b, x):\n",
    "        lin_out = F.linear(x, W, b)\n",
    "        # assume a softplux activation\n",
    "        out     = F.softplus(lin_out)\n",
    "        # for sigmoid only!!!\n",
    "        dz_dx = torch.sigmoid(lin_out)\n",
    "        jac = dz_dx.T.unsqueeze(1)*W.unsqueeze(-1)\n",
    "        return jac, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "18f792ee-cb59-4acf-aa8f-9abcd5d3079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = mlp().double()\n",
    "model_jac = mlp_jac(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "d66377da-7a56-41ce-b1ae-7e94410c5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,10, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "7ed4f17a-f84e-495a-bffd-3d5b32b34193",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_out = torch.autograd.functional.jacobian(model,x)\n",
    "\n",
    "assert (model_jac(x)[0] - jac_out[0,:,0,:]).abs().sum()  < 1e-15\n",
    "assert (model_jac(x)[1] - jac_out[1,:,1,:]).abs().sum()  < 1e-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "a6d8e4f5-e6b3-48a4-b338-f916cef6d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = torch.jit.script(model)\n",
    "sm.save(\"sample_mlp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "5974df99-f1bf-420e-8ae9-ca6e10c73e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_jac = torch.jit.script(model_jac)\n",
    "sm_jac.save(\"sample_mlp_jac.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe27fd0-e6f2-4957-817a-f7227bab4a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "19dc9a83-e543-469a-bf87-5fef794ffd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_output = model_jac(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "162b53a2-8335-492a-b876-52d995beb9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.3412e-02,  9.6209e-03,  1.1615e-03, -1.9757e-03, -5.5300e-02,\n",
       "          -1.5132e-02,  5.0901e-02, -5.1170e-02, -4.9526e-02,  2.9634e-02],\n",
       "         [-7.1423e-03, -1.1505e-02, -3.4237e-03,  3.0132e-03, -4.7993e-03,\n",
       "          -5.8923e-03,  1.2469e-02,  6.7605e-03, -1.0347e-02, -6.1251e-03],\n",
       "         [-1.4138e-02, -2.1848e-02, -6.4179e-03,  7.6606e-03, -8.4621e-03,\n",
       "          -1.3007e-02,  2.5023e-02,  1.2197e-02, -1.9448e-02, -1.1716e-02],\n",
       "         [-9.7071e-03, -1.9917e-02, -5.2517e-03,  2.6016e-02, -9.0773e-03,\n",
       "          -3.2255e-02,  4.3957e-02, -1.0942e-03, -2.3346e-02, -8.3005e-03],\n",
       "         [-3.4236e-02, -1.6066e-02, -3.8222e-03,  1.3716e-02,  1.5369e-02,\n",
       "          -1.0943e-02,  4.6684e-03,  2.0677e-02,  5.0139e-03, -1.6747e-02],\n",
       "         [ 1.9344e-02, -6.1773e-04, -1.5915e-04,  1.4941e-02, -1.6505e-02,\n",
       "          -2.1146e-02,  3.2649e-02, -2.0695e-02, -1.9784e-02,  7.7824e-03],\n",
       "         [-1.1096e-02, -4.0391e-03, -3.7554e-04,  1.8053e-02,  7.1572e-03,\n",
       "          -1.6977e-02,  1.2954e-02, -8.6690e-04,  1.1974e-03, -4.1739e-03],\n",
       "         [-4.2040e-02,  1.1107e-02,  3.8284e-03, -2.3217e-02,  4.6169e-02,\n",
       "           4.0622e-02, -7.5662e-02,  3.7048e-02,  5.5215e-02, -1.3155e-02],\n",
       "         [-5.2600e-03, -1.2695e-03, -7.4233e-04, -1.3063e-02,  2.3949e-03,\n",
       "           1.4351e-02, -1.5520e-02,  1.0839e-02,  4.7353e-03, -3.1610e-03],\n",
       "         [ 2.1973e-02, -1.6934e-03, -1.2279e-03, -3.3755e-03, -2.1259e-02,\n",
       "          -3.6174e-03,  1.8928e-02, -1.2424e-02, -2.0780e-02,  7.2093e-03]],\n",
       "\n",
       "        [[ 7.9310e-02,  8.5922e-03,  6.7327e-04, -2.1352e-03, -6.1515e-02,\n",
       "          -1.7110e-02,  5.7498e-02, -5.4723e-02, -5.6017e-02,  3.1431e-02],\n",
       "         [-4.7936e-03, -1.1407e-02, -3.4682e-03,  2.5573e-03, -6.8041e-03,\n",
       "          -6.0632e-03,  1.4012e-02,  5.3962e-03, -1.2164e-02, -5.2701e-03],\n",
       "         [-1.0180e-02, -2.2044e-02, -6.6089e-03,  6.9060e-03, -1.2195e-02,\n",
       "          -1.3462e-02,  2.8140e-02,  1.0003e-02, -2.3016e-02, -1.0391e-02],\n",
       "         [-8.6699e-03, -2.0260e-02, -5.3712e-03,  2.6511e-02, -1.0290e-02,\n",
       "          -3.3207e-02,  4.5845e-02, -1.9458e-03, -2.4793e-02, -8.0032e-03],\n",
       "         [-3.6809e-02, -1.6412e-02, -3.8503e-03,  1.4220e-02,  1.7332e-02,\n",
       "          -1.0860e-02,  3.3134e-03,  2.2243e-02,  6.6719e-03, -1.7761e-02],\n",
       "         [ 2.0580e-02, -4.2189e-04, -9.7705e-05,  1.5774e-02, -1.7337e-02,\n",
       "          -2.2273e-02,  3.4291e-02, -2.2025e-02, -2.0701e-02,  8.3480e-03],\n",
       "         [-1.4277e-02, -3.4294e-03, -5.1488e-05,  1.9343e-02,  1.0653e-02,\n",
       "          -1.7119e-02,  1.0476e-02,  3.9421e-04,  4.5927e-03, -5.0478e-03],\n",
       "         [-4.9760e-02,  1.2340e-02,  4.3812e-03, -2.4401e-02,  5.4087e-02,\n",
       "           4.4588e-02, -8.5476e-02,  4.2469e-02,  6.3764e-02, -1.5633e-02],\n",
       "         [-3.7147e-03, -1.7885e-03, -9.5476e-04, -1.3216e-02,  5.1304e-04,\n",
       "           1.3841e-02, -1.3551e-02,  1.0045e-02,  2.7034e-03, -2.7782e-03],\n",
       "         [ 2.4615e-02, -2.3314e-03, -1.5077e-03, -3.5546e-03, -2.4225e-02,\n",
       "          -4.4683e-03,  2.2026e-02, -1.3903e-02, -2.3919e-02,  7.9499e-03]]],\n",
       "       dtype=torch.float64, grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00d264-1e80-43dd-b295-f6ceb6787e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487fa58-3157-4ee1-9f39-27a68918db80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5ea0740d-1fc0-4939-9a2d-e11160a74131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5d881d1c-c76e-49ab-98cf-1674ac6ab6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_jac = mlp_jac(model)?\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ea00b22c-e706-414e-9f83-2ab08f857fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_out = torch.autograd.functional.jacobian(model,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "82a9fdde-6053-4ab9-b8d3-e8796a4e9eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mretain_graph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcreate_graph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0monly_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mallow_unused\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Computes and returns the sum of gradients of outputs with respect to\n",
       "the inputs.\n",
       "\n",
       "``grad_outputs`` should be a sequence of length matching ``output``\n",
       "containing the \"vector\" in Jacobian-vector product, usually the pre-computed\n",
       "gradients w.r.t. each of the outputs. If an output doesn't require_grad,\n",
       "then the gradient can be ``None``).\n",
       "\n",
       "If ``only_inputs`` is ``True``, the function will only return a list of gradients\n",
       "w.r.t the specified inputs. If it's ``False``, then gradient w.r.t. all remaining\n",
       "leaves will still be computed, and will be accumulated into their ``.grad``\n",
       "attribute.\n",
       "\n",
       ".. note::\n",
       "\n",
       "    If you run any forward ops, create ``grad_outputs``, and/or call ``grad``\n",
       "    in a user-specified CUDA stream context, see\n",
       "    :ref:`Stream semantics of backward passes<bwd-cuda-stream-semantics>`.\n",
       "\n",
       "Args:\n",
       "    outputs (sequence of Tensor): outputs of the differentiated function.\n",
       "    inputs (sequence of Tensor): Inputs w.r.t. which the gradient will be\n",
       "        returned (and not accumulated into ``.grad``).\n",
       "    grad_outputs (sequence of Tensor): The \"vector\" in the Jacobian-vector product.\n",
       "        Usually gradients w.r.t. each output. None values can be specified for scalar\n",
       "        Tensors or ones that don't require grad. If a None value would be acceptable\n",
       "        for all grad_tensors, then this argument is optional. Default: None.\n",
       "    retain_graph (bool, optional): If ``False``, the graph used to compute the grad\n",
       "        will be freed. Note that in nearly all cases setting this option to ``True``\n",
       "        is not needed and often can be worked around in a much more efficient\n",
       "        way. Defaults to the value of ``create_graph``.\n",
       "    create_graph (bool, optional): If ``True``, graph of the derivative will\n",
       "        be constructed, allowing to compute higher order derivative products.\n",
       "        Default: ``False``.\n",
       "    allow_unused (bool, optional): If ``False``, specifying inputs that were not\n",
       "        used when computing outputs (and therefore their grad is always zero)\n",
       "        is an error. Defaults to ``False``.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.autograd.grad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a955b56-8fa9-4caa-bc46-9373bcd232e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from torch import Tensor\n",
    "class mlp_jac(torch.nn.Module):\n",
    "    def __init__(self, mlp):\n",
    "        super().__init__()\n",
    "        self.mlp = mlp\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        returns = torch.jit.annotate(List[Tensor], [])\n",
    "#         t = torch.jit.annotate(Tensor,torch.zeros(2,10))\n",
    "        out = self.mlp(x)\n",
    "        j = 0\n",
    "        for row in out:\n",
    "            for i in row:\n",
    "                t = torch.autograd.grad([i],[x], retain_graph=True)[0]\n",
    "                returns += [t[j]]\n",
    "            j += 1\n",
    "        return torch.stack(returns).reshape(2,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "083b2927-5bb4-4a2f-8c8d-d5fc48afe266",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29487/2142071969.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "torch.autograd.grad([out[0][0], out[0][1] ], [x], retain_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9803b327-bfc3-4b75-be79-b8b62c90a9c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29487/4237683915.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "out = model(x)\n",
    "torch.autograd.grad([out[0][0]], [x], retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc38681d-57df-4643-b22a-b3f86b50ba84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29487/439931743.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "torch.autograd.grad([out[0][1]], [x], retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4ca4b6-6c4c-4640-92d0-333aedbe3561",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29487/1208969711.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjac_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_jac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "model = mlp().double()\n",
    "jac_model = mlp_jac(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "74091659-d1ce-4282-8eaf-f7324c9e68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,10, dtype=torch.float64, requires_grad=True)\n",
    "out_list = jac_model(x.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "e2980b44-d2fd-4501-bb48-c80c86522d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.2084e-04,  2.2529e-03,  4.0516e-03, -3.1866e-03,  7.0165e-03,\n",
       "          -4.5932e-04,  6.4646e-04,  4.2147e-03,  3.0470e-03, -3.9829e-03],\n",
       "         [ 8.7213e-03, -8.0255e-03, -1.4579e-03,  8.7490e-03, -2.4656e-03,\n",
       "           1.3933e-04,  1.6632e-04,  2.3817e-03,  2.3777e-04,  1.0260e-02],\n",
       "         [ 2.1913e-03, -3.0560e-03, -4.8507e-03,  7.8950e-03, -9.5200e-03,\n",
       "           2.2615e-03,  2.5245e-03, -3.0884e-03, -6.3929e-03,  7.6157e-03],\n",
       "         [-7.3053e-03,  1.0046e-05, -3.8962e-03, -1.2697e-02, -2.6810e-03,\n",
       "          -5.7822e-03, -1.2670e-02, -1.1646e-02,  6.8951e-03, -7.5945e-03],\n",
       "         [-3.7289e-03,  1.1122e-03,  1.2331e-03, -9.8001e-03,  4.6734e-03,\n",
       "          -4.0161e-03, -7.2494e-03, -2.9407e-03,  7.2130e-03, -7.1863e-03],\n",
       "         [ 7.8363e-03, -4.4045e-03,  5.7665e-03,  1.3763e-03,  1.0688e-02,\n",
       "          -1.6565e-03, -5.2603e-04,  9.1066e-03,  7.3450e-03,  2.2714e-03],\n",
       "         [-1.2230e-02,  1.0107e-02, -5.4762e-04, -1.0150e-02, -1.1521e-03,\n",
       "           2.8002e-04, -3.1762e-04, -6.0094e-03, -2.6334e-03, -1.1946e-02],\n",
       "         [-7.5133e-03,  6.9502e-03,  3.5019e-03, -1.1430e-02,  7.0558e-03,\n",
       "          -1.9542e-03, -2.7330e-03, -6.8238e-04,  4.2937e-03, -1.1778e-02],\n",
       "         [-1.0195e-02,  1.1933e-02,  2.2183e-03, -5.6569e-03,  1.5212e-03,\n",
       "           3.1934e-03,  6.2823e-03,  3.3795e-05, -5.9010e-03, -1.0481e-02],\n",
       "         [ 1.5447e-03, -7.1178e-03, -7.4946e-03,  2.1106e-03, -1.0864e-02,\n",
       "          -2.3504e-03, -7.1374e-03, -9.4860e-03,  1.4390e-04,  6.4929e-03]],\n",
       "\n",
       "        [[-3.1357e-04,  2.2559e-03,  4.0446e-03, -3.1482e-03,  6.9921e-03,\n",
       "          -4.3991e-04,  6.8054e-04,  4.2228e-03,  3.0100e-03, -3.9583e-03],\n",
       "         [ 8.7106e-03, -8.0228e-03, -1.4546e-03,  8.7204e-03, -2.4523e-03,\n",
       "           1.2738e-04,  1.4463e-04,  2.3727e-03,  2.5910e-04,  1.0240e-02],\n",
       "         [ 2.1602e-03, -3.0432e-03, -4.8079e-03,  7.7632e-03, -9.4124e-03,\n",
       "           2.2058e-03,  2.4347e-03, -3.0901e-03, -6.2752e-03,  7.5157e-03],\n",
       "         [-7.3063e-03,  8.3502e-06, -3.9367e-03, -1.2632e-02, -2.7682e-03,\n",
       "          -5.7518e-03, -1.2628e-02, -1.1673e-02,  6.8187e-03, -7.5440e-03],\n",
       "         [-3.7021e-03,  1.1135e-03,  1.2122e-03, -9.6886e-03,  4.6042e-03,\n",
       "          -3.9634e-03, -7.1572e-03, -2.9175e-03,  7.1124e-03, -7.1109e-03],\n",
       "         [ 7.8358e-03, -4.3932e-03,  5.7422e-03,  1.4424e-03,  1.0623e-02,\n",
       "          -1.6198e-03, -4.6654e-04,  9.1027e-03,  7.2666e-03,  2.3125e-03],\n",
       "         [-1.2216e-02,  1.0098e-02, -5.4528e-04, -1.0136e-02, -1.1495e-03,\n",
       "           2.8208e-04, -3.1215e-04, -5.9989e-03, -2.6336e-03, -1.1932e-02],\n",
       "         [-7.5321e-03,  6.9877e-03,  3.5056e-03, -1.1407e-02,  7.0425e-03,\n",
       "          -1.9250e-03, -2.6778e-03, -6.6731e-04,  4.2414e-03, -1.1784e-02],\n",
       "         [-1.0114e-02,  1.1826e-02,  2.2103e-03, -5.6542e-03,  1.5421e-03,\n",
       "           3.1422e-03,  6.1878e-03,  2.7707e-05, -5.8032e-03, -1.0421e-02],\n",
       "         [ 1.5488e-03, -7.1210e-03, -7.4947e-03,  2.1146e-03, -1.0865e-02,\n",
       "          -2.3501e-03, -7.1367e-03, -9.4840e-03,  1.4397e-04,  6.4973e-03]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "85a8c163-dc8d-417b-9d7f-6e612f0f31c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\n'Optional[Tensor]' object is not subscriptable:\n  File \"/tmp/ipykernel_33949/1924489597.py\", line 17\n            for i in row:\n                t = torch.autograd.grad([i],[x], retain_graph=True)[0]\n                returns += [t[j]]\n                            ~~~~ <--- HERE\n            j += 1\n        return torch.stack(returns).reshape(2,10,10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_33949/1401950006.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_prepare_scriptable_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         return torch.jit._recursive.create_script_module(\n\u001b[0m\u001b[1;32m   1097\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mconcrete_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_module_concrete_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mAttributeTypeIsSupportedChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mcreate_methods_and_properties_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;31m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0;31m# If done before, hooks can overshadow methods that aren't exported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mproperty_rcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods_and_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_hooks_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hook_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n'Optional[Tensor]' object is not subscriptable:\n  File \"/tmp/ipykernel_33949/1924489597.py\", line 17\n            for i in row:\n                t = torch.autograd.grad([i],[x], retain_graph=True)[0]\n                returns += [t[j]]\n                            ~~~~ <--- HERE\n            j += 1\n        return torch.stack(returns).reshape(2,10,10)\n"
     ]
    }
   ],
   "source": [
    "model = torch.jit.script(jac_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "367af48a-1048-43b1-83b1-c955c6563489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0025,  0.0035,  0.0061,  0.0022,  0.0050,  0.0007,  0.0060,  0.0031,\n",
       "          -0.0022,  0.0062],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[-0.0052, -0.0027,  0.0004, -0.0053, -0.0032, -0.0021,  0.0029, -0.0058,\n",
       "          -0.0030,  0.0079],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[-0.0039,  0.0084, -0.0048, -0.0064, -0.0046,  0.0099, -0.0076, -0.0013,\n",
       "          -0.0001, -0.0021],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.0040, -0.0047,  0.0011,  0.0057,  0.0029, -0.0051,  0.0016,  0.0026,\n",
       "           0.0021, -0.0041],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.0069, -0.0037,  0.0059,  0.0089,  0.0074, -0.0064,  0.0067,  0.0055,\n",
       "           0.0010, -0.0004],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[-0.0073,  0.0014, -0.0011, -0.0087, -0.0051,  0.0025,  0.0004, -0.0067,\n",
       "          -0.0037,  0.0086],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[-0.0051,  0.0014, -0.0077, -0.0063, -0.0073,  0.0047, -0.0088, -0.0042,\n",
       "           0.0013, -0.0051],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[-0.0015, -0.0065, -0.0010, -0.0004, -0.0018, -0.0055,  0.0012, -0.0032,\n",
       "           0.0001,  0.0005],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.0030, -0.0046,  0.0020,  0.0045,  0.0028, -0.0053,  0.0030,  0.0016,\n",
       "           0.0010, -0.0012],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.0002,  0.0078,  0.0047, -0.0013,  0.0030,  0.0054,  0.0035,  0.0022,\n",
       "          -0.0030,  0.0071],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000]], dtype=torch.float64),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0055,  0.0050,  0.0083,  0.0054,  0.0082,  0.0009,  0.0075,  0.0063,\n",
       "          -0.0018,  0.0055]], dtype=torch.float64),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [-0.0084, -0.0042, -0.0017, -0.0088, -0.0064, -0.0023,  0.0017, -0.0092,\n",
       "          -0.0036,  0.0090]], dtype=torch.float64),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-3.3305e-03,  8.8058e-03, -4.4806e-03, -5.8029e-03, -4.1004e-03,\n",
       "           1.0105e-02, -7.5089e-03, -6.2557e-04, -4.5630e-05, -2.3158e-03]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0044, -0.0046,  0.0013,  0.0061,  0.0032, -0.0052,  0.0017,  0.0029,\n",
       "           0.0021, -0.0042]], dtype=torch.float64),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0094, -0.0027,  0.0076,  0.0115,  0.0099, -0.0064,  0.0078,  0.0081,\n",
       "           0.0014, -0.0011]], dtype=torch.float64),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-1.0692e-02,  9.9877e-05, -3.1521e-03, -1.2389e-02, -8.4467e-03,\n",
       "           2.4710e-03, -8.2021e-04, -1.0245e-02, -4.4358e-03,  1.0061e-02]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [-0.0078,  0.0003, -0.0097, -0.0092, -0.0101,  0.0047, -0.0102, -0.0071,\n",
       "           0.0009, -0.0045]], dtype=torch.float64),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [-4.4062e-03, -7.9318e-03, -2.9471e-03, -3.4311e-03, -4.7375e-03,\n",
       "          -5.6884e-03,  3.9740e-05, -6.3440e-03, -3.6570e-04,  1.4364e-03]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0031, -0.0047,  0.0020,  0.0046,  0.0028, -0.0054,  0.0031,  0.0016,\n",
       "           0.0010, -0.0012]], dtype=torch.float64),\n",
       " tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000],\n",
       "         [ 0.0032,  0.0091,  0.0066,  0.0019,  0.0060,  0.0055,  0.0047,  0.0054,\n",
       "          -0.0024,  0.0061]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,10, dtype=torch.float64, requires_grad=True)\n",
    "model(x.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cfeb210-b609-496f-b48f-9661dfddf491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "02bb245a-222c-4f26-95f7-ec3ddb3bc7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class onelayer_mlp(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = torch.nn.Sequential(\n",
    "            OrderedDict([\n",
    "                ('linear1', torch.nn.Linear(3, 8)),\n",
    "                ('activation1', torch.nn.Sigmoid()),\n",
    "                ('linear2', torch.nn.Linear(8, 5)),\n",
    "                ('activation2', torch.nn.Sigmoid()),\n",
    "            ])\n",
    "#             torch.nn.Linear(3,10),\n",
    "#             torch.nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "307472c0-e0fe-41d7-9d6d-6901a39957ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp_jac(torch.nn.Module):\n",
    "    def __init__(self, mlp):\n",
    "        super().__init__()        \n",
    "        self.mlp = mlp.net\n",
    "\n",
    "        self.linear1 = self.mlp[0]\n",
    "        self.linear2 = self.mlp[2]\n",
    "        \n",
    "        self.linear1_weight = self.linear1.weight\n",
    "        self.linear1_bias   = self.linear1.bias\n",
    "        \n",
    "        self.linear2_weight = self.linear2.weight\n",
    "        self.linear2_bias   = self.linear2.bias\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "        jac1, out1 = self.jacobian_onelayer(self.linear1_weight, self.linear1_bias, x)\n",
    "        jac2, out2 = self.jacobian_onelayer(self.linear2_weight, self.linear2_bias, out1)\n",
    "        \n",
    "        jacs = torch.bmm(jac2.permute(2,0,1),jac1.permute(2,0,1))\n",
    "        return jacs\n",
    "#         jacs = torch.einsum(\"xyb, yzb-> xzb\", output_jac2, output_jac1)\n",
    "        \n",
    "        return jac1, jac2\n",
    "    \n",
    "    def jacobian_onelayer(self, W, b, x):\n",
    "        lin_out = F.linear(x, W, b)\n",
    "        out     = torch.sigmoid(lin_out)\n",
    "        # for sigmoid only!!!\n",
    "        dz_dx = out* (1 - out)\n",
    "        jac = dz_dx.T.unsqueeze(1)*W.unsqueeze(-1)\n",
    "        return jac, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "0946da4a-2255-4a57-890c-603e0083709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1     = onelayer_mlp()\n",
    "mlp1_jac = mlp_jac(mlp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "108c4f08-7114-4da9-8a52-3a528ab9de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "23f354ad-32f0-4273-a542-8ddd97a1ca2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0072, -0.0018,  0.0078],\n",
       "        [ 0.0020,  0.0017,  0.0005],\n",
       "        [-0.0027,  0.0145, -0.0197],\n",
       "        [-0.0045, -0.0025,  0.0069],\n",
       "        [-0.0049,  0.0053, -0.0059]])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_true = torch.autograd.functional.jacobian(mlp1,x)\n",
    "jac_true[0,:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "c01498f0-0020-4ac2-9e71-e15bcde9d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "8b5c6c97-eb58-4e84-b020-72e80807fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# out1 = (mlp1.net(x))\n",
    "# w = mlp1.net[0].weight\n",
    "# do_dz = out1* (1 - out1)\n",
    "# jac = do_dz.T.unsqueeze(1)*w.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "44440d92-92f3-4826-bbf6-460dc320fb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 2])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "dbd4a497-7967-42f0-bf28-9914dd895570",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1_jac = mlp_jac(mlp1)\n",
    "output_jac = mlp1_jac(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "28930001-6023-40da-99cb-b19b82811083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "16e6fe61-4a3a-4369-a6cd-e609da063db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = torch.jit.script(mlp1_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "7bc46e83-9f8a-47c1-b9db-e45d547fa7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa.save(\"mlp1_jac.ptc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "3aadeaf6-7403-434e-b00a-492b9b149d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_script = torch.jit.load(\"sample_mlp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "62d61f98-0b56-46e7-ab61-3628b6996802",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29487/125797274.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp_jac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_script\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_29487/641062252.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mlp)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_magic_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__getitem__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mforward_magic_method\u001b[0;34m(self, method_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mRecursiveScriptModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             ):\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_jac(mlp_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "6b08750b-88c1-4583-a4e0-70d582b46ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.ParameterDict at 0x7fdc24bf5130>"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_script._parameters.__dict__['_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd7a38-706f-4667-9551-82b3eaaa77d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
